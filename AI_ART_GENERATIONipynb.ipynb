{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGWJY4KjMfVn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "import PIL.Image\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image # Python Image Library is a library that adds support for opening, manipulating, and saving many different\n",
        "                      # image file formats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "gVs2teiDMl7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained inceptionNet model, for more information on Transfer Learning, check previous case studies\n",
        "base_model = tf.keras.applications.InceptionV3(include_top = False, weights = 'imagenet')"
      ],
      "metadata": {
        "id": "VHJAjN5GMnf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the first image\n",
        "# Source: https://www.pxfuel.com/en/free-photo-xxgfs\n",
        "img_1 = Image.open(\"/mars.jpg\")\n",
        "\n",
        "# Open the second image\n",
        "# Source: https://commons.wikimedia.org/wiki/File:Georges_Garen_embrasement_tour_Eiffel.jpg\n",
        "img_2 = Image.open('eiffel.jpg')\n",
        "\n",
        "# Blend the two images\n",
        "\n",
        "image = Image.blend(img_1, img_2, 0.5) # alpha --> The interpolation alpha factor. If alpha is 0.0, a copy of the first image is returned.\n",
        "# If alpha is 1.0, a copy of the second image is returned.\n",
        "\n",
        "# Save the blended image\n",
        "image.save(\"img_0.jpg\")"
      ],
      "metadata": {
        "id": "fP3jn1g0MpeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "Sample_Image = tf.keras.preprocessing.image.load_img('img_0.jpg')"
      ],
      "metadata": {
        "id": "3Op5JlXOMrBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sample_Image"
      ],
      "metadata": {
        "id": "k6uvo2-VMvm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy array\n",
        "Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)\n",
        "\n",
        "# Sample_Image = np.array(Sample_Image)"
      ],
      "metadata": {
        "id": "WiwvswYUMw4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the max and min values\n",
        "print('min pixel values = {}, max pixel values = {}'.format(Sample_Image.min(), Sample_Image.max()))"
      ],
      "metadata": {
        "id": "-PIyk0qXMzMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the input image\n",
        "Sample_Image = np.array(Sample_Image)/255.0\n",
        "Sample_Image.shape"
      ],
      "metadata": {
        "id": "65iv9juTM2KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's verify normalized images values!\n",
        "print('min pixel values = {}, max pixel values = {}'.format(Sample_Image.min(), Sample_Image.max()))"
      ],
      "metadata": {
        "id": "L-XfjQXHM3me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sample_Image = tf.expand_dims(Sample_Image, axis = 0)"
      ],
      "metadata": {
        "id": "B8tr-HW3M5CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(Sample_Image)"
      ],
      "metadata": {
        "id": "G0Q4DUT7M6zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "id": "hBfCY1C0M8Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximize the activations of these layers\n",
        "\n",
        "names = ['mixed3', 'mixed5', 'mixed7']\n",
        "\n",
        "# names = ['mixed3']\n",
        "\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "deepdream_model = tf.keras.Model(inputs = base_model.input, outputs = layers)"
      ],
      "metadata": {
        "id": "Mujv7VAOND3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deepdream_model.summary()"
      ],
      "metadata": {
        "id": "vCpkgV2xNEXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's run the model by feeding in our input image and taking a look at the activations \"Neuron outputs\"\n",
        "activations = deepdream_model(Sample_Image)\n",
        "activations"
      ],
      "metadata": {
        "id": "aOUEHhYZNFsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DEEP DREAM ALGROTHIM"
      ],
      "metadata": {
        "id": "XTljhCAnNHJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(image, model):\n",
        "# Function used for loss calculations\n",
        "# It works by feedforwarding the input image through the network and generate activations\n",
        "# Then obtain the average and sum of those outputs\n",
        "\n",
        "  img_batch = tf.expand_dims(image, axis=0) # Convert into batch format\n",
        "  layer_activations = model(img_batch) # Run the model\n",
        "  print('ACTIVATION VALUES (LAYER OUTPUT) =\\n', layer_activations)\n",
        "  # print('ACTIVATION SHAPE =\\n', np.shape(layer_activations))\n",
        "\n",
        "  losses = [] # accumulator to hold all the losses\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act) # calculate mean of each activation\n",
        "    losses.append(loss)\n",
        "\n",
        "  print('LOSSES (FROM MULTIPLE ACTIVATION LAYERS) = ', losses)\n",
        "  print('LOSSES SHAPE (FROM MULTIPLE ACTIVATION LAYERS) = ', np.shape(losses))\n",
        "  print('SUM OF ALL LOSSES (FROM ALL SELECTED LAYERS)= ', tf.reduce_sum(losses))\n",
        "\n",
        "  return  tf.reduce_sum(losses) # Calculate sum"
      ],
      "metadata": {
        "id": "XVpHANcDNQSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = calc_loss(tf.Variable(Sample_Image), deepdream_model)"
      ],
      "metadata": {
        "id": "Fv3wfZZrNSA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss # Sum up the losses from both activations"
      ],
      "metadata": {
        "id": "Uoqa4WOVNTZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When you annotate a function with tf.function, the function can be called like any other python defined function.\n",
        "# The benefit is that it will be compiled into a graph so it will be much faster and could be executed over TPU/GPU\n",
        "\n",
        "@tf.function\n",
        "def deepdream(model, image, step_size):\n",
        "    with tf.GradientTape() as tape:\n",
        "      # This needs gradients relative to `img`\n",
        "      # `GradientTape` only watches `tf.Variable`s by default\n",
        "      tape.watch(image)\n",
        "      loss = calc_loss(image, model) # call the function that calculate the loss\n",
        "\n",
        "    # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "    # The syntax is as follows: dy_dx = g.gradient(y, x)\n",
        "    gradients = tape.gradient(loss, image)\n",
        "\n",
        "    print('GRADIENTS =\\n', gradients)\n",
        "    print('GRADIENTS SHAPE =\\n', np.shape(gradients))\n",
        "\n",
        "    # tf.math.reduce_std computes the standard deviation of elements across dimensions of a tensor\n",
        "    gradients /= tf.math.reduce_std(gradients)\n",
        "\n",
        "    # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "    # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "    image = image + gradients * step_size\n",
        "    image = tf.clip_by_value(image, -1, 1)\n",
        "\n",
        "    return loss, image"
      ],
      "metadata": {
        "id": "GZyaXF17NVX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_deep_dream_simple(model, image, steps = 100, step_size = 0.01):\n",
        "  # Convert from uint8 to the range expected by the model.\n",
        "  image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
        "\n",
        "  for step in range(steps):\n",
        "    loss, image = deepdream(model, image, step_size)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "      plt.figure(figsize=(12,12))\n",
        "      plt.imshow(deprocess(image))\n",
        "      plt.show()\n",
        "      print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "  # clear_output(wait=True)\n",
        "  plt.figure(figsize=(12,12))\n",
        "  plt.imshow(deprocess(image))\n",
        "  plt.show()\n",
        "\n",
        "  return deprocess(image)"
      ],
      "metadata": {
        "id": "Lnfwg8mDNflP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deprocess(image):\n",
        "  image = 255*(image + 1.0)/2.0\n",
        "  return tf.cast(image, tf.uint8)\n"
      ],
      "metadata": {
        "id": "v_gWIkK1NgOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Load the image again and convert it to Numpy array\n",
        "Sample_Image = np.array(tf.keras.preprocessing.image.load_img('img_0.jpg'))\n",
        "dream_img = run_deep_dream_simple(model = deepdream_model, image = Sample_Image, steps = 4000, step_size = 0.001)\n"
      ],
      "metadata": {
        "id": "yhb1r4dtNhvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.preprocessing.image.load_img(\"img_0.jpg\")"
      ],
      "metadata": {
        "id": "e1bp_P2JNjdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "E8tDLkskNmfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Name of the folder\n",
        "dream_name = 'mars_eiffel'"
      ],
      "metadata": {
        "id": "BWTGg1g1No4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Blended image dimension\n",
        "\n",
        "x_size = 910 # larger the image longer is going to take to fetch the frames\n",
        "y_size = 605"
      ],
      "metadata": {
        "id": "NmYESEFFN3EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Counters\n",
        "created_count = 0\n",
        "max_count = 50"
      ],
      "metadata": {
        "id": "fzabRx15N4wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This helper function loads an image and returns it as a numpy array of floating points\n",
        "\n",
        "def load_image(filename):\n",
        "    image = PIL.Image.open(filename)\n",
        "    return np.float32(image)"
      ],
      "metadata": {
        "id": "joST5isGN6SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 50):\n",
        "    # Make sure to create a new folder entitled 'mars_eiffel' and place img_0 in it\n",
        "    # Get into the dream directory and look for the number of images and then figure out what is the latest image. Hence this\n",
        "    # image we are going to start with and let it dream on and on\n",
        "\n",
        "    if os.path.isfile('/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i+1)):\n",
        "        print(\"{} present already, continue fetching the frames...\".format(i+1))\n",
        "\n",
        "    else:\n",
        "        # Call the load image funtion\n",
        "        img_result = load_image(r'/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i))\n",
        "\n",
        "\n",
        "        # Zoom the image\n",
        "        x_zoom = 2 # this indicates how quick the zoom is\n",
        "        y_zoom = 1\n",
        "\n",
        "        # Chop off the edges of the image and resize the image back to the original shape. This gives the visual changes of a zoom\n",
        "        img_result = img_result[0+x_zoom : y_size-y_zoom, 0+y_zoom : x_size-x_zoom]\n",
        "        img_result = cv2.resize(img_result, (x_size, y_size))\n",
        "\n",
        "        # Adjust the RGB value of the image\n",
        "        img_result[:, :, 0] += 2  # red\n",
        "        img_result[:, :, 1] += 2  # green\n",
        "        img_result[:, :, 2] += 2  # blue\n",
        "\n",
        "        # Deep dream model\n",
        "        img_result = run_deep_dream_simple(model = deepdream_model, image = img_result, steps = 500, step_size = 0.001)\n",
        "\n",
        "        # Clip the image, convert the datatype of the array, and then convert to an actual image.\n",
        "        img_result = np.clip(img_result, 0.0, 255.0)\n",
        "        img_result = img_result.astype(np.uint8)\n",
        "        result = PIL.Image.fromarray(img_result, mode='RGB')\n",
        "\n",
        "        # Save all the frames in the dream location\n",
        "        result.save(r'/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i+1))\n",
        "\n",
        "        created_count += 1\n",
        "        if created_count > max_count:\n",
        "            break"
      ],
      "metadata": {
        "id": "ZRfpxNTPN7l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR VIDEO"
      ],
      "metadata": {
        "id": "VoY32wAjOPPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "Wp5o7losN88m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the folder\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_name = \"mars_eiffel.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "id": "ywNno6x-OCUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of all the frames\n",
        "\n",
        "dream_path = 'mars_eiffel'"
      ],
      "metadata": {
        "id": "3BhF3IwNODsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the codec and create VideoWriter object\n",
        "# Download FFmeg\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') # FourCC is a 4-byte code used to specify the video codec\n",
        "\n",
        "out = cv2.VideoWriter('deepdreamvideo.avi', fourcc , 5.0, (910, 605)) # Specify the fourCC, frames per second (fps),\n",
        "                                                                            # and frame size\n",
        "# The frames per second value is depends on few important things\n",
        "# 1. The number of frames we have created. Less number of frames brings small fps\n",
        "# 2. The larger the image the bigger the fps value. For example, 1080 pixel image can bring 60 fps"
      ],
      "metadata": {
        "id": "rgUHKApJOFbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9999999999999):\n",
        "\n",
        "    # Get into the dream directory and looks for the number of images and then figure out what is the latest image. Hence with\n",
        "    # this image we are going to start with and let it dream on and on\n",
        "    if os.path.isfile('mars_eiffel/img_{}.jpg'.format(i+1)):\n",
        "        pass\n",
        "    # Figure out how long the dream is\n",
        "    else:\n",
        "        dream_length = i\n",
        "        break"
      ],
      "metadata": {
        "id": "uOcT37cgOHi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dream_length"
      ],
      "metadata": {
        "id": "SHQQOi_yOI7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(dream_length):\n",
        "\n",
        "    # Build the frames of cv2.VideoWriter\n",
        "    img_path = os.path.join(dream_path,'img_{}.jpg'.format(i)) # join the dream path\n",
        "\n",
        "    print(img_path) # print the image path\n",
        "\n",
        "    frame = cv2.imread(img_path)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "S6Dp9ZGZOKjx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}